{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jesuslovesyou21/bigdata/blob/main/prac2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Mxd4jjG-_O1D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523,
          "referenced_widgets": [
            "3377e77bdcb84598ae1bf482b454651a",
            "a82045ff0dc24f398443d46cb8968ae3",
            "b3924b6fad9b4bd9851acdb6d87cf302",
            "a3f653341662461cb13d1f2c91e0b4d5",
            "3fc19b20d543443ba9630283cb0a95aa",
            "db02d70e990a47f4b4d52bbca13005c1",
            "e5bec12fc9654bb6af9c00bc716334a6",
            "1be53a28cb904296bef2e4cd20d8d414",
            "61b4e686a4da478e8ba5a1bba0b56f3f",
            "e74ea4c7639c4549a3871442f0c33f54",
            "416c29813fe24f1e854d4766a04a14b5"
          ]
        },
        "outputId": "9ba090d5-6c76-4405-e07b-575898e61dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3377e77bdcb84598ae1bf482b454651a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Invalid pattern: '**' can only be an entire path component",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-042a36e9361d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# ✅ 1. IMDB 영화 리뷰 데이터셋 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# IMDB는 'train'과 'test'로 나뉜 binary classification용 감성 데이터셋\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imdb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# ✅ 2. 과적합 방지를 위한 균형잡힌 샘플링\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2113\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1796\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1799\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m                         \u001b[0;34mf\"Couldn't find '{path}' on the Hugging Face Hub either: {type(e1).__name__}: {e1}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m                     ) from None\n\u001b[0;32m-> 1495\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m         raise FileNotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m                     \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m                     \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m                 ).get_module()\n\u001b[0m\u001b[1;32m   1480\u001b[0m         except (\n\u001b[1;32m   1481\u001b[0m             \u001b[0mException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mget_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mget_data_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         )\n\u001b[1;32m   1036\u001b[0m         data_files = DataFilesDict.from_patterns(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mget_data_patterns\u001b[0;34m(base_path, download_config)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolve_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_data_files_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEmptyDatasetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The directory at {base_path} doesn't contain any data files\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36m_get_data_files_patterns\u001b[0;34m(pattern_resolver)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mpattern\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m                     \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_path_and_storage_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fs_token_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0mfs_base_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_marker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mfs_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"::\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"://\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/core.py\u001b[0m in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_expand_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"expand_info\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"detail\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"revision\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     def find(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/spec.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mallpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithdirs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mends_with_sep\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fsspec/utils.py\u001b[0m in \u001b[0;36mglob_translate\u001b[0;34m(pat)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m\"**\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    732\u001b[0m                 \u001b[0;34m\"Invalid pattern: '**' can only be an entire path component\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Invalid pattern: '**' can only be an entire path component"
          ]
        }
      ],
      "source": [
        "# ✅ 필요한 라이브러리 임포트\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "import torch\n",
        "\n",
        "# ✅ 1. IMDB 영화 리뷰 데이터셋 로드\n",
        "# IMDB는 'train'과 'test'로 나뉜 binary classification용 감성 데이터셋\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# ✅ 2. 과적합 방지를 위한 균형잡힌 샘플링\n",
        "# 아래 방식으로 데이터 훈련/테스트 세트 선택 할 경우 데이터 편향으로 인한 과적합 또는 오적합 발생\n",
        "# train_data = dataset[\"train\"].select(range(2000))  # 메모리 초과 방지용\n",
        "# test_data = dataset[\"test\"].select(range(500))     # 메모리 초과 방지용\n",
        "# 원본 train 데이터는 부정(0) 리뷰가 앞쪽에 몰려 있음 ⇒ 모델 편향 유발\n",
        "# 따라서 부정/긍정 각각 5000개씩 무작위 추출하여 균형 유지\n",
        "neg_samples = dataset[\"train\"].filter(lambda x: x['label'] == 0).shuffle(seed=42).select(range(5000))\n",
        "pos_samples = dataset[\"train\"].filter(lambda x: x['label'] == 1).shuffle(seed=42).select(range(5000))\n",
        "\n",
        "# 부정/긍정 결합 후 다시 셔플하여 train 데이터 구성\n",
        "balanced_dataset = concatenate_datasets([neg_samples, pos_samples]).shuffle(seed=42)\n",
        "\n",
        "# ✅ 3. 학습/평가용 데이터 분리\n",
        "# 학습 데이터: 균형 샘플 중 2,000개 사용 (Colab 환경 고려)\n",
        "# 테스트 데이터: 원본 IMDB test 데이터 중 500개 사용\n",
        "train_data = balanced_dataset.select(range(2000))\n",
        "test_data = load_dataset(\"imdb\")[\"test\"].select(range(500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J46WuS-L4PIl"
      },
      "outputs": [],
      "source": [
        "# ✂️ 훈련 데이터셋에서 리뷰 텍스트와 라벨만 분리하여 별도 변수에 저장\n",
        "train_texts = train_data[\"text\"]   # 리뷰 본문 텍스트 목록 (리스트 형태)\n",
        "train_labels = train_data[\"label\"] # 감성 레이블 (0: 부정, 1: 긍정)\n",
        "\n",
        "# 🔤 사전학습된 BERT용 토크나이저 로드 (WordPiece 기반 토큰화)\n",
        "# 'bert-base-uncased'는 모든 텍스트를 소문자로 처리함\n",
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# ✂️ 최대 시퀀스 길이 설정 (너무 긴 문장은 자르고, 짧은 문장은 패딩함)\n",
        "MAX_LEN = 256\n",
        "\n",
        "# 🧪 토크나이저로 문장들을 BERT 입력 형태로 변환\n",
        "# truncation=True → 길면 자르기 / padding='max_length' → 짧으면 256길이에 맞춰 패딩\n",
        "# return_tensors=\"pt\" → PyTorch 텐서 형태로 반환\n",
        "encodings = tokenizer(\n",
        "    train_texts,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "\n",
        "# 🔠 인코딩 결과에서 input_ids와 attention_mask 추출\n",
        "# input_ids: 토큰의 정수 인덱스\n",
        "# attention_mask: 패딩이 아닌 부분은 1, 패딩된 부분은 0\n",
        "train_inputs = encodings[\"input_ids\"]\n",
        "train_masks = encodings[\"attention_mask\"]\n",
        "\n",
        "# 🏷️ 라벨도 torch 텐서 형태로 변환 (모델 학습에 사용하기 위함)\n",
        "train_labels = torch.tensor(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpDjUc87DMax"
      },
      "outputs": [],
      "source": [
        "# 🧳 PyTorch Dataset 및 Dataloader 구성\n",
        "\n",
        "# 한 번에 학습할 데이터 수 설정 (미니 배치 크기)\n",
        "batch_size = 16\n",
        "\n",
        "# 📦 TensorDataset: 입력 데이터(input_ids), 마스크(attention_mask), 정답 라벨(labels)을 하나의 Dataset으로 묶음\n",
        "# => 학습 시 각 인덱스에 대해 (input_ids, attention_mask, label)을 반환\n",
        "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "\n",
        "# 🚚 DataLoader: 실제 학습에서 배치 단위로 데이터를 공급해주는 역할\n",
        "# RandomSampler: 매 epoch마다 데이터를 **무작위로 섞어** 샘플링 → 학습 성능 향상에 도움\n",
        "# batch_size: 한 배치에 포함될 샘플 수\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,                     # 학습할 데이터셋\n",
        "    sampler=RandomSampler(train_dataset),  # 랜덤 샘플링 (epoch마다 데이터 순서 섞기)\n",
        "    batch_size=batch_size             # 한 번에 읽어올 샘플 개수 (배치 단위)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yat1wnGb32td"
      },
      "outputs": [],
      "source": [
        "# 🔧 GPU 사용 여부 확인\n",
        "# CUDA가 사용 가능하면 GPU 사용, 그렇지 않으면 CPU 사용\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 🧠 사전학습된 BERT 분류 모델 로딩\n",
        "# 'bert-base-uncased': 소문자화된 BERT 사전학습 모델\n",
        "# num_labels=2: 이진 분류 문제 (긍정/부정)\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# 모델을 선택한 장치(GPU 또는 CPU)로 이동\n",
        "model.to(device)\n",
        "\n",
        "# 🔁 옵티마이저 및 학습률 스케줄러 설정\n",
        "# AdamW: BERT 논문에서 권장하는 옵티마이저 (가중치 감쇠 적용)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "# 총 학습 epoch 수 설정\n",
        "epochs = 2\n",
        "\n",
        "# 전체 학습 스텝 수 계산 (총 배치 수 × epoch 수)\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 학습률 스케줄러 설정\n",
        "# Warm-up 없이 선형 감소 방식으로 학습률 조정\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,                 # 사용할 옵티마이저\n",
        "    num_warmup_steps=0,        # warm-up 단계 없음\n",
        "    num_training_steps=total_steps  # 전체 학습 스텝 수\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmzZQ6s-G3_s"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# 🧬 랜덤 시드 고정 (결과 재현 가능성을 높이기 위함)\n",
        "seed_val = 777\n",
        "random.seed(seed_val)                    # 파이썬 random 고정\n",
        "np.random.seed(seed_val)                # 넘파이 random 고정\n",
        "torch.manual_seed(seed_val)             # PyTorch random 고정\n",
        "torch.cuda.manual_seed_all(seed_val)    # CUDA에서도 동일하게 시드 고정\n",
        "\n",
        "# 학습 시간 포맷 함수 (초 → 시:분:초)\n",
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round(elapsed))))\n",
        "\n",
        "# 🏋️ 모델 학습 시작\n",
        "model.train()  # 모델을 학습 모드로 전환 (Dropout, BatchNorm 등이 학습 모드로 작동)\n",
        "\n",
        "# 각 epoch 반복\n",
        "for epoch_i in range(epochs):\n",
        "    print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
        "    t0 = time.time()  # 학습 시작 시간 저장\n",
        "    total_loss = 0    # 누적 손실 초기화\n",
        "\n",
        "    # 미니배치 반복\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 매 100스텝마다 경과 시간 출력\n",
        "        if step % 100 == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(f\"  ▶ Step {step}/{len(train_dataloader)} - Elapsed: {elapsed}\")\n",
        "\n",
        "        # 입력 데이터와 라벨을 장치(GPU/CPU)로 이동\n",
        "        b_input_ids, b_input_mask, b_labels = [b.to(device) for b in batch]\n",
        "\n",
        "        model.zero_grad()  # 기울기 초기화\n",
        "\n",
        "        # 🔁 순전파 → 손실 계산\n",
        "        outputs = model(\n",
        "            b_input_ids,\n",
        "            attention_mask=b_input_mask,\n",
        "            labels=b_labels\n",
        "        )\n",
        "        loss = outputs.loss         # CrossEntropyLoss 포함\n",
        "        total_loss += loss.item()   # 손실 누적\n",
        "\n",
        "        # 🔄 역전파 → 가중치 갱신\n",
        "        loss.backward()  # 손실 기준으로 역전파 수행\n",
        "\n",
        "        # 그래디언트 클리핑: exploding gradient 방지\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()  # 가중치 업데이트\n",
        "        scheduler.step()  # 학습률 조정\n",
        "\n",
        "    # ⏱ 에폭 단위 평균 손실 출력\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    print(f\"✅ Epoch {epoch_i+1} Avg Loss: {avg_loss:.4f}\")\n",
        "    print(f\"🕒 Epoch time: {format_time(time.time() - t0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sARw6t0G-bq"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 📍 GPU 사용 가능 여부 확인 → GPU가 있으면 0, 없으면 CPU(-1)로 설정\n",
        "device_id = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "# 🤖 학습된 모델로 파이프라인 구성\n",
        "clf_pipeline = pipeline(\n",
        "    task=\"text-classification\",        # 작업 유형: 문장 분류\n",
        "    model=model,                       # fine-tuning된 BERT 분류 모델\n",
        "    tokenizer=tokenizer,               # 같은 base의 토크나이저 사용\n",
        "    device=device_id,                  # 디바이스 설정: GPU or CPU\n",
        "    return_all_scores=True,            # 두 클래스의 확률 모두 출력\n",
        "    function_to_apply=\"softmax\"        # 출력 로짓 → 확률값으로 변환\n",
        ")\n",
        "\n",
        "# 🔍 예측할 테스트 문장 리스트\n",
        "sample_texts = [\n",
        "    \"This movie was absolutely fantastic. I loved the plot and the characters.\",   # 긍정\n",
        "    \"It was the worst film I have ever seen. Completely boring.\",                  # 부정\n",
        "    \"Not bad, but not great either. Just okay.\"                                    # 중립에 가까움 (판단 애매)\n",
        "]\n",
        "\n",
        "# 🧾 파이프라인을 통해 예측 수행\n",
        "predictions = clf_pipeline(sample_texts)\n",
        "\n",
        "# 📋 각 문장별 예측 결과 출력\n",
        "for text, result in zip(sample_texts, predictions):\n",
        "    print(f\"\\n📌 입력 문장: {text}\")\n",
        "    for label in result:\n",
        "        print(f\"  {label['label']} → {label['score']:.4f}\")  # label: POSITIVE/NEGATIVE, score: 확률값"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOQt_wQTISa8"
      },
      "outputs": [],
      "source": [
        "Device set to use cuda:0\n",
        "\n",
        "📌 입력 문장: This movie was absolutely fantastic. I loved the plot and the characters.\n",
        "  LABEL_0 → 0.0199\n",
        "  LABEL_1 → 0.9801\n",
        "\n",
        "📌 입력 문장: It was the worst film I have ever seen. Completely boring.\n",
        "  LABEL_0 → 0.9772\n",
        "  LABEL_1 → 0.0228\n",
        "\n",
        "📌 입력 문장: Not bad, but not great either. Just okay.\n",
        "  LABEL_0 → 0.3401\n",
        "  LABEL_1 → 0.6599"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wWT9koUIvOJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# 🎯 테스트셋 전처리\n",
        "test_texts = test_data[\"text\"]             # 테스트 문장 리스트\n",
        "test_labels = test_data[\"label\"]           # 테스트 레이블 리스트\n",
        "\n",
        "# 🧪 토크나이징 및 인코딩 (훈련과 동일하게 max_length 기준 padding/truncation 수행)\n",
        "test_encodings = tokenizer(\n",
        "    test_texts,\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors=\"pt\"                    # PyTorch 텐서 형태로 반환\n",
        ")\n",
        "\n",
        "test_inputs = test_encodings[\"input_ids\"]         # 입력 토큰 ID\n",
        "test_masks = test_encodings[\"attention_mask\"]     # 어텐션 마스크\n",
        "test_labels_tensor = torch.tensor(test_labels)    # 정답 레이블\n",
        "\n",
        "# 📦 PyTorch용 테스트 Dataset 및 DataLoader 구성\n",
        "test_dataset = TensorDataset(test_inputs, test_masks, test_labels_tensor)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
        "\n",
        "# 📈 평가 함수 정의\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()              # 평가 모드 (Dropout/BatchNorm 등 비활성화)\n",
        "    preds = []                # 예측값 저장용 리스트\n",
        "    true_labels = []          # 실제값 저장용 리스트\n",
        "\n",
        "    for batch in dataloader:\n",
        "        # 미니배치 데이터를 GPU/CPU로 이동\n",
        "        b_input_ids, b_input_mask, b_labels = [b.to(device) for b in batch]\n",
        "\n",
        "        with torch.no_grad():  # 그래디언트 계산 비활성화 (속도↑, 메모리↓)\n",
        "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=1).cpu().numpy()  # 가장 확률 높은 클래스 선택\n",
        "        labels = b_labels.cpu().numpy()\n",
        "\n",
        "        preds.extend(predictions)      # 예측 결과 누적\n",
        "        true_labels.extend(labels)     # 실제 레이블 누적\n",
        "\n",
        "    return preds, true_labels\n",
        "\n",
        "# 🧪 평가 실행\n",
        "preds, true_labels = evaluate_model(model, test_dataloader)\n",
        "\n",
        "# ✅ 정확도 및 F1 점수 계산 및 출력\n",
        "acc = accuracy_score(true_labels, preds)                         # 정확도: 예측과 실제 일치 비율\n",
        "f1 = f1_score(true_labels, preds, average='weighted')            # F1 점수: 정밀도와 재현율의 조화 평균\n",
        "\n",
        "print(f\"\\n✅ Test Accuracy: {acc:.4f}\")\n",
        "print(f\"✅ Test F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gIx1nj5IyJl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcHqrUXTeK8E0lAIf1AEiH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3377e77bdcb84598ae1bf482b454651a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a82045ff0dc24f398443d46cb8968ae3",
              "IPY_MODEL_b3924b6fad9b4bd9851acdb6d87cf302",
              "IPY_MODEL_a3f653341662461cb13d1f2c91e0b4d5"
            ],
            "layout": "IPY_MODEL_3fc19b20d543443ba9630283cb0a95aa"
          }
        },
        "a82045ff0dc24f398443d46cb8968ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db02d70e990a47f4b4d52bbca13005c1",
            "placeholder": "​",
            "style": "IPY_MODEL_e5bec12fc9654bb6af9c00bc716334a6",
            "value": "Downloading readme: 100%"
          }
        },
        "b3924b6fad9b4bd9851acdb6d87cf302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be53a28cb904296bef2e4cd20d8d414",
            "max": 7809,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61b4e686a4da478e8ba5a1bba0b56f3f",
            "value": 7809
          }
        },
        "a3f653341662461cb13d1f2c91e0b4d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e74ea4c7639c4549a3871442f0c33f54",
            "placeholder": "​",
            "style": "IPY_MODEL_416c29813fe24f1e854d4766a04a14b5",
            "value": " 7.81k/7.81k [00:00&lt;00:00, 207kB/s]"
          }
        },
        "3fc19b20d543443ba9630283cb0a95aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db02d70e990a47f4b4d52bbca13005c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5bec12fc9654bb6af9c00bc716334a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1be53a28cb904296bef2e4cd20d8d414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61b4e686a4da478e8ba5a1bba0b56f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e74ea4c7639c4549a3871442f0c33f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "416c29813fe24f1e854d4766a04a14b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}